{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "split-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import init_datasets, _init_corpora\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "crucial-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 7\n",
    "batch_size = 3\n",
    "data = torch.LongTensor(list(range(1, 75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "recent-holocaust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
       "        55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "        73, 74])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "differential-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequence_Data(Dataset):\n",
    "    def __init__(self, x:torch.LongTensor, y:torch.LongTensor):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.len = x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dressed-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_io_sequences(sequence: np.ndarray, time_steps: int) -> Tuple:\n",
    "    \"\"\"\n",
    "    :param sequence: sequence of integer representation of words\n",
    "    :param time_steps: number of time steps in LSTM cell\n",
    "    :return: Tuple of torch tensors of shape (n, time_steps)\n",
    "    \"\"\"\n",
    "    sequence = torch.LongTensor(sequence)\n",
    "\n",
    "    # from seq we generate 2 copies.\n",
    "    inputs, targets = sequence, sequence[1:]\n",
    "\n",
    "    # split seq into seq of of size time_steps\n",
    "    inputs = torch.split(tensor=inputs, split_size_or_sections=time_steps)\n",
    "    targets = torch.split(tensor=targets, split_size_or_sections=time_steps)\n",
    "\n",
    "    # note: word2index['<pad>'] = 0\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=0)\n",
    "\n",
    "    return (inputs_padded, targets_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "detected-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _old_generate_io_sequences(data:np.ndarray, time_steps:int) -> Tuple:# -> List[Tuple]:\n",
    "    \"\"\"\n",
    "    :param data: sequence of integer representation of words\n",
    "    :param time_steps: number of time steps in LSTM cell\n",
    "    :return: Tuple of torch tensors of shape (n, time_steps, 1)\n",
    "    \"\"\"\n",
    "    data = torch.LongTensor(data)\n",
    "    # split tensor into tensors of of size time_steps\n",
    "    data = torch.split(tensor=data, split_size_or_sections=time_steps)\n",
    "\n",
    "    # note: word2index['<pad>'] = 0\n",
    "    sequences = pad_sequence(data, batch_first=True, padding_value=0)\n",
    "\n",
    "    # from seq we generate 2 copies.\n",
    "    # inputs=seq[:-1], targets=seq[1:]\n",
    "    sequences_inputs = sequences.narrow_copy(1, 0, sequences.shape[1] - 1)\n",
    "    sequences_targets = sequences.narrow_copy(1, 1, sequences.shape[1] - 1)\n",
    "\n",
    "    return (sequences_inputs, sequences_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "interpreted-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, t = _generate_io_sequences(data, 7)\n",
    "i2, t2 = _old_generate_io_sequences(data, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "attempted-idaho",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19, 20, 21],\n",
      "        [22, 23, 24, 25, 26, 27, 28],\n",
      "        [29, 30, 31, 32, 33, 34, 35],\n",
      "        [36, 37, 38, 39, 40, 41, 42],\n",
      "        [43, 44, 45, 46, 47, 48, 49],\n",
      "        [50, 51, 52, 53, 54, 55, 56],\n",
      "        [57, 58, 59, 60, 61, 62, 63],\n",
      "        [64, 65, 66, 67, 68, 69, 70],\n",
      "        [71, 72, 73, 74,  0,  0,  0]])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 8,  9, 10, 11, 12, 13],\n",
      "        [15, 16, 17, 18, 19, 20],\n",
      "        [22, 23, 24, 25, 26, 27],\n",
      "        [29, 30, 31, 32, 33, 34],\n",
      "        [36, 37, 38, 39, 40, 41],\n",
      "        [43, 44, 45, 46, 47, 48],\n",
      "        [50, 51, 52, 53, 54, 55],\n",
      "        [57, 58, 59, 60, 61, 62],\n",
      "        [64, 65, 66, 67, 68, 69],\n",
      "        [71, 72, 73, 74,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "print(i)\n",
    "print(i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "specialized-stream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  3,  4,  5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12, 13, 14, 15],\n",
      "        [16, 17, 18, 19, 20, 21, 22],\n",
      "        [23, 24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35, 36],\n",
      "        [37, 38, 39, 40, 41, 42, 43],\n",
      "        [44, 45, 46, 47, 48, 49, 50],\n",
      "        [51, 52, 53, 54, 55, 56, 57],\n",
      "        [58, 59, 60, 61, 62, 63, 64],\n",
      "        [65, 66, 67, 68, 69, 70, 71],\n",
      "        [72, 73, 74,  0,  0,  0,  0]])\n",
      "tensor([[ 2,  3,  4,  5,  6,  7],\n",
      "        [ 9, 10, 11, 12, 13, 14],\n",
      "        [16, 17, 18, 19, 20, 21],\n",
      "        [23, 24, 25, 26, 27, 28],\n",
      "        [30, 31, 32, 33, 34, 35],\n",
      "        [37, 38, 39, 40, 41, 42],\n",
      "        [44, 45, 46, 47, 48, 49],\n",
      "        [51, 52, 53, 54, 55, 56],\n",
      "        [58, 59, 60, 61, 62, 63],\n",
      "        [65, 66, 67, 68, 69, 70],\n",
      "        [72, 73, 74,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "print(t)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "silver-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = len(i) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "biblical-ottawa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "asian-judgment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "treated-geometry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19, 20, 21],\n",
       "        [22, 23, 24, 25, 26, 27, 28],\n",
       "        [29, 30, 31, 32, 33, 34, 35],\n",
       "        [36, 37, 38, 39, 40, 41, 42],\n",
       "        [43, 44, 45, 46, 47, 48, 49],\n",
       "        [50, 51, 52, 53, 54, 55, 56],\n",
       "        [57, 58, 59, 60, 61, 62, 63]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "weekly-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = i[:num_batches*batch_size]\n",
    "targets = t[:num_batches*batch_size]\n",
    "inputs2 = i2[:num_batches*batch_size]\n",
    "targets2 = t2[:num_batches*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "average-yellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19, 20, 21],\n",
      "        [22, 23, 24, 25, 26, 27, 28],\n",
      "        [29, 30, 31, 32, 33, 34, 35],\n",
      "        [36, 37, 38, 39, 40, 41, 42],\n",
      "        [43, 44, 45, 46, 47, 48, 49],\n",
      "        [50, 51, 52, 53, 54, 55, 56],\n",
      "        [57, 58, 59, 60, 61, 62, 63]])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 8,  9, 10, 11, 12, 13],\n",
      "        [15, 16, 17, 18, 19, 20],\n",
      "        [22, 23, 24, 25, 26, 27],\n",
      "        [29, 30, 31, 32, 33, 34],\n",
      "        [36, 37, 38, 39, 40, 41],\n",
      "        [43, 44, 45, 46, 47, 48],\n",
      "        [50, 51, 52, 53, 54, 55],\n",
      "        [57, 58, 59, 60, 61, 62]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "structural-attention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  3,  4,  5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12, 13, 14, 15],\n",
      "        [16, 17, 18, 19, 20, 21, 22],\n",
      "        [23, 24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35, 36],\n",
      "        [37, 38, 39, 40, 41, 42, 43],\n",
      "        [44, 45, 46, 47, 48, 49, 50],\n",
      "        [51, 52, 53, 54, 55, 56, 57],\n",
      "        [58, 59, 60, 61, 62, 63, 64]])\n",
      "tensor([[ 2,  3,  4,  5,  6,  7],\n",
      "        [ 9, 10, 11, 12, 13, 14],\n",
      "        [16, 17, 18, 19, 20, 21],\n",
      "        [23, 24, 25, 26, 27, 28],\n",
      "        [30, 31, 32, 33, 34, 35],\n",
      "        [37, 38, 39, 40, 41, 42],\n",
      "        [44, 45, 46, 47, 48, 49],\n",
      "        [51, 52, 53, 54, 55, 56],\n",
      "        [58, 59, 60, 61, 62, 63]])\n"
     ]
    }
   ],
   "source": [
    "print(targets)\n",
    "print(targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "described-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Sequence_Data(x=inputs, y=targets)\n",
    "dataset2 = Sequence_Data(x=inputs2, y=targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "decent-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "data_loader2 = DataLoader(dataset=dataset2, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "saved-audience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(data_loader))\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "incorporate-hands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size : 3\n",
      "input sequences : tensor([[36, 37, 38, 39, 40, 41, 42],\n",
      "        [29, 30, 31, 32, 33, 34, 35],\n",
      "        [50, 51, 52, 53, 54, 55, 56]])\n",
      "target sequences : tensor([[37, 38, 39, 40, 41, 42, 43],\n",
      "        [30, 31, 32, 33, 34, 35, 36],\n",
      "        [51, 52, 53, 54, 55, 56, 57]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"batch size : {batch_size}\")\n",
    "print(f\"input sequences : {x[0]}\")\n",
    "print(f\"target sequences : {x[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "married-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36, 37, 38, 39, 40, 41],\n",
       "        [15, 16, 17, 18, 19, 20],\n",
       "        [50, 51, 52, 53, 54, 55]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = next(iter(data_loader2))\n",
    "x2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "artificial-numbers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size : 3\n",
      "input sequences : tensor([[36, 37, 38, 39, 40, 41],\n",
      "        [15, 16, 17, 18, 19, 20],\n",
      "        [50, 51, 52, 53, 54, 55]])\n",
      "target sequences : tensor([[37, 38, 39, 40, 41, 42],\n",
      "        [16, 17, 18, 19, 20, 21],\n",
      "        [51, 52, 53, 54, 55, 56]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"batch size : {batch_size}\")\n",
    "print(f\"input sequences : {x2[0]}\")\n",
    "print(f\"target sequences : {x2[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hybrid-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _intlist_to_dataloader(data:np.ndarray, time_steps:int, batch_size:int) -> DataLoader:\n",
    "    \"\"\"\n",
    "    :param data: input list of integers\n",
    "    :param batch_size: hyper parameter, for minibatch size\n",
    "    :param time_steps: hyper parameter for sequence length for bptt\n",
    "    :return: DataLoader for SGD\n",
    "    \"\"\"\n",
    "    # given int list, generate input and output sequences of length = time_steps\n",
    "    inputs, targets = _old_generate_io_sequences(sequence=data, time_steps=time_steps)\n",
    "    \n",
    "    # cut off any data that will create incomplete batches\n",
    "    num_batches = len(inputs) // batch_size\n",
    "    inputs = inputs[:num_batches*batch_size]\n",
    "    targets = targets[:num_batches*batch_size]\n",
    "    \n",
    "    # create Dataset object\n",
    "    dataset = Sequence_Data(x=inputs, y=targets)\n",
    "\n",
    "    # create dataloader\n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-knight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
